{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = \"\"\"\n",
    "SQL Alchemy versus SQL model these two\n",
    "top OMS are about to battle it out to\n",
    "see which one is best and why you should\n",
    "choose one over the other this is a\n",
    "great comparison because SQL Alchemy has\n",
    "been the goat greatest of all time of\n",
    "python omms for years while SQL model is\n",
    "a new Contender built on top of SQL\n",
    "Alchemy but adding the power of pantic\n",
    "and data validation in this video we'll\n",
    "be breaking down these two omms across\n",
    "three main categories one we're going to\n",
    "be comparing the complexity of the two\n",
    "then we're going to dive into the\n",
    "learning curve to be able to use them\n",
    "and then three we're going to go into\n",
    "the community and the ecosystem of both\n",
    "of these orms each of these categories\n",
    "will be scored based on specific\n",
    "subcategories and we'll dive into all\n",
    "the details as we go along in this video\n",
    "if you're new to the channel I'm Eric\n",
    "Roby a software engineer with over a\n",
    "decade of experience and I've helped\n",
    "thousands of developers learn and grow\n",
    "within their craft now before we dive in\n",
    "it's it's important to note that SQL\n",
    "model is built on top of SQL Alchemy so\n",
    "if you use SQL model you're using SQL\n",
    "Alchemy under the hood for instance a\n",
    "SQL model is still a SQL Alchemy model\n",
    "but the reverse isn't true SQL model is\n",
    "not in SQL Alchemy but SQL Alchemy is in\n",
    "SQL model this comparison is still\n",
    "relevant because the way you use these\n",
    "orms is fundamentally different so let's\n",
    "start with why does SQL Alchemy and SQL\n",
    "model even exist SQL Alchemy is a\n",
    "comprehens hensive object relational\n",
    "mapping tool for python it's been the\n",
    "goat of python omm since 2005 and it's\n",
    "the most widely used library for\n",
    "database access in Python SQL Alchemy\n",
    "lets developers interact with databases\n",
    "using python code instead of writing raw\n",
    "SQL queries in the application\n",
    "themselves this allows python developers\n",
    "to be able to focus on writing python\n",
    "instead of having to worry about writing\n",
    "SQL its flexibility is what's made at\n",
    "the Top Choice for database Management\n",
    "Systems in Python 4 years on the other\n",
    "hand SQL model is a newer om combined\n",
    "with the best of SQL Alchemy with pantic\n",
    "and pantic is known for being able to do\n",
    "data validation so we're doing data\n",
    "validation right before we change data\n",
    "within a table in fun fact SQL model was\n",
    "created by the same person who created\n",
    "fast API but now let's kick off this\n",
    "competition starting with category one\n",
    "which is complexity now complexity in my\n",
    "mind is really built from two different\n",
    "subcategories so complexity is built\n",
    "from ease of use in the feature set\n",
    "given to this tool so SQL Alchemy is\n",
    "incredibly powerful but that power comes\n",
    "with a steep learning curve in my\n",
    "opinion the setup of session managements\n",
    "the omm mechanics these can all be\n",
    "fairly daunting for new developers that\n",
    "are trying to complete simple tasks in\n",
    "contrast SQL model is designed with\n",
    "Simplicity in mind and that's why it has\n",
    "pantic for data validation then it can\n",
    "use typ hints which just makes\n",
    "everything easier if you know python EX\n",
    "especially for developers who like\n",
    "really know modern python practices SQL\n",
    "Alchemy then also offers a comprehensive\n",
    "set of features and this allows for you\n",
    "to have like fine grain control over\n",
    "database operations it allows you be\n",
    "able to merge tables very easily and be\n",
    "able to do complex relationships and\n",
    "then you can also like optimize queries\n",
    "this makes it ideal for like really\n",
    "complex applications that are really\n",
    "database heavy while SQL model on the\n",
    "other hand really their main features is\n",
    "for common tasks but it doesn't offer\n",
    "really the same depth of control as\n",
    "something like a SQL Alchemy does and\n",
    "this is particularly true for like\n",
    "complex queries and databased\n",
    "interactions so overall if I'm going to\n",
    "score SQL Alchemy and SQL model based on\n",
    "complexity I'm going to give SQL Alchemy\n",
    "a 6.5 out of 10 and I'm going to give\n",
    "SQL model a 7.5 out of 10 and that's\n",
    "because SQL model has pantic and most\n",
    "people only need to do like beginner and\n",
    "medium like level queries and the\n",
    "complexity is not always needed this\n",
    "brings the overall score as of right now\n",
    "SQL Alchemy 6.5 and SQL model 7.5 but\n",
    "now let's talk about the category number\n",
    "two which is the learning curve and when\n",
    "I think of like a learning curve like\n",
    "how hard something is to learn I want to\n",
    "see like how easy it is to get started\n",
    "and then once you're past getting\n",
    "started how hard is it to learn\n",
    "intermediate things so SQL Alchemy has a\n",
    "steep learning curve that we've already\n",
    "talked about which is particularly true\n",
    "for beginners and the framework\n",
    "complexity in the OR mechanics session\n",
    "management and all that kind of stuff\n",
    "requires significant time to really\n",
    "Master if you want to be like a master\n",
    "at SQL Alchemy it does take some time\n",
    "while I think it's easier to become like\n",
    "a master at SQL model and that's because\n",
    "there's not as much complexity at the\n",
    "top SQL Alchemy can do more but I think\n",
    "the getting started entry level of SQL\n",
    "model is a little bit easier however as\n",
    "developers gain experience SQL model SQL\n",
    "Alchemy becomes more manageable however\n",
    "when trying to master its Advanced\n",
    "features like complex relationships and\n",
    "performance optimizations this still\n",
    "requires really deep understanding of\n",
    "both SQL Alchemy and SQL SQL model while\n",
    "easier initially just isn't really used\n",
    "in production applications enough to\n",
    "really be able to compare the complexity\n",
    "of like once you master SQL model where\n",
    "I'm going to say SQL Alchemy got a 7 out\n",
    "of 10 and a SQL model got 6.5 this\n",
    "brings the overall score to 12.5 to 13\n",
    "so SQL model still winning by just a\n",
    "little bit going into the last round now\n",
    "category three is community and that's\n",
    "really broken up into size and the\n",
    "entire ecosystem SQL Alchemy has been\n",
    "integral to the python ecosystem like I\n",
    "said since 2005 it's been the goat since\n",
    "and because it's been the goat it's\n",
    "built a huge I mean large and active\n",
    "Community the active Community has\n",
    "contributed to many plugins extensions\n",
    "documentations there's tutorials\n",
    "everywhere SQL Alchemy is very very\n",
    "popular SQL model since it's newer\n",
    "doesn't yet have the same level of\n",
    "community support it is growing rapidly\n",
    "like it's very new it's growing rapidly\n",
    "just does not have as much you know\n",
    "Community as SQL Alchemy but it's\n",
    "growing rapidly like if you use fast API\n",
    "fast API is growing rapidly and now all\n",
    "the documentation is getting used with\n",
    "SQL model since it's used by the same\n",
    "developer it is starting to gain lots\n",
    "and lots of traction and since SQL\n",
    "alchemy's ecosystem is mature and\n",
    "extensive with a wide range of tools\n",
    "this helps with migration and testing\n",
    "and performance optimization it's been\n",
    "proven in production over and over again\n",
    "SQL Alchemy is being used by I mean 90%\n",
    "of python applications that might be\n",
    "high but it's very very popular SQL\n",
    "models ecosystem is still in its early\n",
    "stage it's benefiting tremendously from\n",
    "Fast API and pantic but lacking the\n",
    "breadth like the SQL Alchemy tools and\n",
    "community that SQL Alchemy is known for\n",
    "so overall when it comes to community\n",
    "and ecosystem I'm going to have to give\n",
    "SQL Alchemy an 8.5 out of 10 and SQL\n",
    "model only a 6.5 this brings the overall\n",
    "score of SQL Alchemy to 21 and SQL model\n",
    "to 20.5 so in the end SQL Alchemy does\n",
    "have a small Edge overall to SQL model\n",
    "and this is largely due to the community\n",
    "and being proven in production SQL model\n",
    "just is not being used in a production\n",
    "application yet enough as of right now\n",
    "however if you're developing a project\n",
    "with fast API because it's built by the\n",
    "same developer I'm going to give a\n",
    "slight Edge to SQL model maybe like one\n",
    "and a half half points which now puts\n",
    "SQL model maybe 22 to 21 overall but as\n",
    "of right now I'm still probably not\n",
    "going to be using SQL model in\n",
    "production until it's proven out to be a\n",
    "little bit more stable and a little bit\n",
    "more used and with that they're almost\n",
    "identical you can use whichever you want\n",
    "cheers\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.output_parsers import JsonOutputParser, PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# from .state import AgentState\n",
    "from langchain_core.runnables import RunnableConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def motes(content):\n",
    "    \"\"\"\n",
    "    To generate a list of notes from the content\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Generate a list of notes from the content provided in json format and return the list of notes.  \n",
    "    \"\"\")\n",
    "\n",
    "    try:\n",
    "        # Get condition content\n",
    "        condition_content = state[\"property_condition\"]\n",
    "        if not condition_content:\n",
    "            error_msg = f\"No property condition content found\"\n",
    "            return {\n",
    "                **state,\n",
    "                \"condition_output\": ConditionState(\n",
    "                    access_concerns_score=0.0,\n",
    "                    topo_concerns_score=0.0,\n",
    "                    structure_concerns_score=0.0,\n",
    "                    other_concerns_score=0.0,\n",
    "                    total_score=0.0,\n",
    "                    feedback=error_msg,\n",
    "                    analyzed_text=\"\"\n",
    "                ),\n",
    "                \"messages\": state.get(\"messages\", []) + [\n",
    "                    SystemMessage(content=error_msg)\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "        condition_text = \"\\n\".join(condition_content)\n",
    "        \n",
    "        # Setup chain\n",
    "        json_llm = llm.bind(response_format={\"type\": \"json_object\"})\n",
    "        chain = prompt | json_llm | JsonOutputParser()\n",
    "\n",
    "        # Run analysis\n",
    "        analysis = chain.invoke({\"condition_text\": condition_text, \"content\": state[\"content\"]}, modifiedConfig)\n",
    "        # print(\"Analysis:\", analysis)\n",
    "\n",
    "        # Format for printing\n",
    "        formatted_json = json.dumps(analysis, indent=4)\n",
    "        print(formatted_json)\n",
    "        \n",
    "        # Create ConditionState\n",
    "        condition_state = ConditionState(\n",
    "            access_concerns_score=1.0,  # Automatic 1 point\n",
    "            topo_concerns_score=1.0,    # Automatic 1 point\n",
    "            structure_concerns_score=1.0, # Automatic 1 point\n",
    "            other_concerns_score=1.0,    # Automatic 1 point\n",
    "            total_score=4.0,            # Total of all scores\n",
    "            feedback=analysis[\"feedback\"],\n",
    "            analyzed_text=analysis[\"analyzed_text\"]\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        print(\"Exiting Condition Node.....\")\n",
    "\n",
    "        return updated_state\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error analyzing property condition: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"condition_output\": ConditionState(\n",
    "                access_concerns_score=0.0,\n",
    "                topo_concerns_score=0.0,\n",
    "                structure_concerns_score=0.0,\n",
    "                other_concerns_score=0.0,\n",
    "                total_score=0.0,\n",
    "                feedback=error_msg,\n",
    "                analyzed_text=\"\"\n",
    "            ),\n",
    "            \"messages\": state.get(\"messages\", []) + [\n",
    "                SystemMessage(content=error_msg)\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "# # Test\n",
    "# result = condition(test_state)\n",
    "# print(\"Condition Analysis Results:\")\n",
    "# formatted_json = json.dumps(result[\"condition_output\"], indent=4)\n",
    "# print(formatted_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Note(BaseModel):\n",
    "    \"\"\"Structure for individual notes\"\"\"\n",
    "    title: str = Field(description=\"Note section title\")\n",
    "    content: str = Field(description=\"Main content of note\")\n",
    "    keywords: List[str] = Field(description=\"Key terms from note\")\n",
    "    importance_score: float = Field(ge=0, le=1, description=\"Importance score between 0-1\")\n",
    "\n",
    "class NotesOutput(BaseModel):\n",
    "    \"\"\"Structure for complete notes output\"\"\"\n",
    "    notes: List[Note]\n",
    "    summary: str\n",
    "    total_score: float\n",
    "    feedback: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(transcript: str, config: Optional[RunnableConfig] = None) -> dict:\n",
    "    \"\"\"\n",
    "    Generate structured notes from transcript content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize LLM and parser\n",
    "        llm = ChatOpenAI(temperature=0.7)\n",
    "        json_parser = JsonOutputParser()\n",
    "\n",
    "        # Create prompt template with properly escaped JSON structure\n",
    "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        Analyze this transcript and create structured notes:\n",
    "        \n",
    "        Transcript: {transcript}\n",
    "\n",
    "        Create detailed notes following this structure:\n",
    "        1. Break into logical sections\n",
    "        2. Extract key points and concepts\n",
    "        3. Identify important keywords\n",
    "        4. Assign importance scores\n",
    "\n",
    "        Return analysis in this exact JSON format:\n",
    "        {{\n",
    "            \"notes\": [\n",
    "                {{\n",
    "                    \"title\": \"Section Title\",\n",
    "                    \"content\": \"Main points and key concepts\",\n",
    "                    \"keywords\": [\"keyword1\", \"keyword2\"],\n",
    "                    \"importance_score\": 0.8\n",
    "                }}\n",
    "            ],\n",
    "            \"summary\": \"Brief overview of main points\",\n",
    "            \"total_score\": 0.85,\n",
    "            \"feedback\": \"Analysis feedback and recommendations\"\n",
    "        }}\n",
    "        \"\"\")\n",
    "\n",
    "        # Setup processing chain\n",
    "        json_llm = llm.bind(response_format={\"type\": \"json_object\"})\n",
    "        chain = prompt | json_llm | json_parser\n",
    "\n",
    "        # Process transcript\n",
    "        result = chain.invoke({\"transcript\": transcript}, config)\n",
    "\n",
    "        # Convert to Pydantic model\n",
    "        notes_output = NotesOutput(\n",
    "            notes=[Note(**note) for note in result[\"notes\"]],\n",
    "            summary=result[\"summary\"],\n",
    "            total_score=result[\"total_score\"],\n",
    "            feedback=result.get(\"feedback\", \"\")\n",
    "        )\n",
    "\n",
    "        return notes_output.model_dump()\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Failed to generate notes: {str(e)}\"\n",
    "        print(f\"Error: {error_msg}\")\n",
    "        \n",
    "        return {\n",
    "            \"notes\": [],\n",
    "            \"summary\": \"\",\n",
    "            \"total_score\": 0.0,\n",
    "            \"feedback\": error_msg,\n",
    "            \"error\": True\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generate_notes(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"notes\": [\n",
      "        {\n",
      "            \"title\": \"Introduction\",\n",
      "            \"content\": \"Comparison between SQL Alchemy and SQL Model, focusing on complexity, learning curve, and community. SQL Model built on top of SQL Alchemy. SQL Alchemy widely used for database access in Python.\",\n",
      "            \"keywords\": [\n",
      "                \"SQL Alchemy\",\n",
      "                \"SQL Model\",\n",
      "                \"complexity\",\n",
      "                \"learning curve\",\n",
      "                \"community\",\n",
      "                \"Python\"\n",
      "            ],\n",
      "            \"importance_score\": 0.9\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Complexity Comparison\",\n",
      "            \"content\": \"SQL Alchemy offers fine-grain control over database operations and complex relationships. SQL Model designed with simplicity in mind, with data validation through pantic. SQL Model scores higher in simplicity.\",\n",
      "            \"keywords\": [\n",
      "                \"control\",\n",
      "                \"relationships\",\n",
      "                \"data validation\",\n",
      "                \"simplicity\"\n",
      "            ],\n",
      "            \"importance_score\": 0.85\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Learning Curve\",\n",
      "            \"content\": \"SQL Alchemy has a steep learning curve, especially for beginners. SQL Model easier to get started with, but SQL Alchemy offers more advanced features. SQL Model easier for beginners, SQL Alchemy better for advanced users.\",\n",
      "            \"keywords\": [\n",
      "                \"beginners\",\n",
      "                \"advanced features\",\n",
      "                \"learning curve\",\n",
      "                \"SQL Alchemy\",\n",
      "                \"SQL Model\"\n",
      "            ],\n",
      "            \"importance_score\": 0.8\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Community and Ecosystem\",\n",
      "            \"content\": \"SQL Alchemy has a large and active community, with extensive ecosystem. SQL Model growing rapidly but lacks the breadth of tools and community support compared to SQL Alchemy. SQL Alchemy proven in production.\",\n",
      "            \"keywords\": [\n",
      "                \"community\",\n",
      "                \"ecosystem\",\n",
      "                \"tools\",\n",
      "                \"production\",\n",
      "                \"SQL Alchemy\",\n",
      "                \"SQL Model\"\n",
      "            ],\n",
      "            \"importance_score\": 0.9\n",
      "        }\n",
      "    ],\n",
      "    \"summary\": \"SQL Model scores higher in simplicity, SQL Alchemy better for advanced users. SQL Alchemy has a larger and more established community and ecosystem, proven in production.\",\n",
      "    \"total_score\": 0.85\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "formatted_json = json.dumps(output, indent=4)\n",
    "print(formatted_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotesOutput(BaseModel):\n",
    "    \"\"\"Summary of given input\"\"\"\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(transcript: str, config: Optional[RunnableConfig] = None) -> dict:\n",
    "    \"\"\"\n",
    "    Summarize given transcript content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize LLM and parser\n",
    "        llm = ChatOpenAI(temperature=0.7)\n",
    "        json_parser = JsonOutputParser()\n",
    "\n",
    "        # Create prompt template with properly escaped JSON structure\n",
    "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        Analyze this transcript and create summary of it:\n",
    "        \n",
    "        Input: {transcript}\n",
    "\n",
    "        Create a concise summary of the main points and key concepts.\n",
    "\n",
    "        Return analysis in this exact JSON format:\n",
    "        {{\n",
    "            \"summary\": \"Concise summary of main points\"\n",
    "        }}\n",
    "        \"\"\")\n",
    "\n",
    "        # Setup processing chain\n",
    "        json_llm = llm.bind(response_format={\"type\": \"json_object\"})\n",
    "        chain = prompt | json_llm | json_parser\n",
    "\n",
    "        # Process transcript\n",
    "        result = chain.invoke({\"transcript\": transcript}, config)\n",
    "\n",
    "        # Convert to Pydantic model\n",
    "        notes_output = NotesOutput(\n",
    "            summary=result[\"summary\"]\n",
    "        )\n",
    "\n",
    "        return notes_output.model_dump()\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Failed to generate notes: {str(e)}\"\n",
    "        print(f\"Error: {error_msg}\")\n",
    "        \n",
    "        return {\n",
    "            \"summary\": \"\",\n",
    "            \"error\": True\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"summary\": \"The transcript compares SQL Alchemy and SQL model, two top Object Relational Mapping tools for Python. SQL Alchemy has been the preferred choice since 2005, known for its power and flexibility. SQL model, a newer contender built on top of SQL Alchemy, offers simplicity and data validation with the use of pantic. The comparison is based on complexity, learning curve, and community/ecosystem. SQL model scores slightly higher in complexity and learning curve, while SQL Alchemy has a larger and more mature community. Ultimately, SQL Alchemy has a slight edge due to its proven track record in production applications.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "summary_output = generate_notes(transcript)\n",
    "formatted_json = json.dumps(summary_output, indent=4)\n",
    "print(formatted_json)\n",
    "\n",
    "summ = summary_output[\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs import play\n",
    "from elevenlabs.client import ElevenLabs\n",
    "\n",
    "client = ElevenLabs(\n",
    "  api_key=\"sk_ec209b32fd7ff532ed8b3faf1939a2339f9a81851f54234c\", # Defaults to ELEVEN_API_KEY\n",
    ")\n",
    "\n",
    "audio = client.generate(\n",
    "  text=summ,\n",
    "  voice=\"Brian\",\n",
    "  model=\"eleven_multilingual_v2\"\n",
    ")\n",
    "# play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to: audio_files\\my_audio.mp3\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import tempfile\n",
    "from typing import Optional, Union, Generator, Any, Dict\n",
    "import os\n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "# Map ElevenLabs formats to file extensions\n",
    "FORMAT_EXTENSIONS: Dict[str, str] = {\n",
    "    'mp3_22050_32': 'mp3',\n",
    "    'mp3_44100_32': 'mp3',\n",
    "    'mp3_44100_64': 'mp3',\n",
    "    'mp3_44100_96': 'mp3',\n",
    "    'mp3_44100_128': 'mp3',\n",
    "    'mp3_44100_192': 'mp3',\n",
    "    'pcm_16000': 'wav',\n",
    "    'pcm_22050': 'wav',\n",
    "    'pcm_24000': 'wav',\n",
    "    'pcm_44100': 'wav',\n",
    "    'ulaw_8000': 'wav'\n",
    "}\n",
    "\n",
    "def save_and_play_audio(\n",
    "    audio_data: Union[bytes, Generator[Any, None, None]],\n",
    "    output_dir: Optional[str] = None,\n",
    "    filename: Optional[str] = None,\n",
    "    extension: str = \"mp3_44100_128\",\n",
    "    auto_play: bool = False\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Save audio data to file and optionally play it\n",
    "    \n",
    "    Args:\n",
    "        audio_data: Raw audio bytes or generator from ElevenLabs\n",
    "        output_dir: Directory to save file (default: system temp dir)\n",
    "        filename: Custom filename (default: timestamp)\n",
    "        extension: ElevenLabs output format (default: mp3_44100_128)\n",
    "        auto_play: Whether to attempt playback (default: False)\n",
    "    \n",
    "    Returns:\n",
    "        Path to saved audio file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set output directory\n",
    "        if output_dir is None:\n",
    "            output_dir = tempfile.gettempdir()\n",
    "        \n",
    "        # Generate filename if not provided\n",
    "        if filename is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"audio_{timestamp}\"\n",
    "            \n",
    "        # Get correct file extension from format\n",
    "        file_extension = FORMAT_EXTENSIONS.get(extension, 'mp3')\n",
    "            \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Create full file path\n",
    "        file_path = Path(output_dir) / f\"{filename}.{file_extension}\"\n",
    "        \n",
    "        # Create buffer for collecting generator output\n",
    "        buffer = io.BytesIO()\n",
    "        \n",
    "        # Save audio data\n",
    "        try:\n",
    "            if isinstance(audio_data, (bytes, bytearray)):\n",
    "                buffer.write(audio_data)\n",
    "            else:\n",
    "                # Handle generator by collecting chunks\n",
    "                for chunk in audio_data:\n",
    "                    if isinstance(chunk, (bytes, bytearray)):\n",
    "                        buffer.write(chunk)\n",
    "                    else:\n",
    "                        raise TypeError(f\"Generator must yield bytes, not {type(chunk)}\")\n",
    "                        \n",
    "            # Write collected data to file\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(buffer.getvalue())\n",
    "                \n",
    "        finally:\n",
    "            buffer.close()\n",
    "            \n",
    "        print(f\"Audio saved to: {file_path}\")\n",
    "        \n",
    "        # Optional playback attempt using system default player\n",
    "        if auto_play:\n",
    "            try:\n",
    "                import platform\n",
    "                system = platform.system()\n",
    "                \n",
    "                if system == 'Darwin':       # macOS\n",
    "                    os.system(f'open \"{file_path}\"')\n",
    "                elif system == 'Windows':    # Windows\n",
    "                    os.system(f'start \"\" \"{file_path}\"')\n",
    "                elif system == 'Linux':      # Linux\n",
    "                    os.system(f'xdg-open \"{file_path}\"')\n",
    "            except Exception as e:\n",
    "                print(f\"Could not auto-play file: {e}\")\n",
    "                \n",
    "        return str(file_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to save audio: {e}\")\n",
    "\n",
    "# Usage with ElevenLabs\n",
    "client = ElevenLabs(api_key=\"\")\n",
    "audio = client.generate(\n",
    "    text=summ,\n",
    "    voice=\"Brian\",\n",
    "    model=\"eleven_multilingual_v2\",\n",
    "    output_format=\"mp3_44100_128\"\n",
    ")\n",
    "\n",
    "file_path = save_and_play_audio(\n",
    "    audio_data=audio,\n",
    "    output_dir=\"./audio_files\",\n",
    "    filename=\"my_audio\",\n",
    "    extension=\"mp3_44100_128\",\n",
    "    auto_play=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
